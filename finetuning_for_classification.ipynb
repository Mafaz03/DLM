{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308fb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from helper import *\n",
    "from knowledge_transfer import load_weights_into_gpt\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from model import GPTModel\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afd91d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already downloaded\n"
     ]
    }
   ],
   "source": [
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extract_path = \"sms_spam_collection\"\n",
    "data_fite_path = Path(extract_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "if not os.path.exists(\"sms_spam_collection/SMSSpamCollection.tsv\"):\n",
    "    url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "    \n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open (zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "        f.extractall(extract_path)\n",
    "\n",
    "    original_file_path = Path(extract_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_fite_path)\n",
    "\n",
    "    os.remove(zip_path)\n",
    "    print(\"file downloaded just now\")\n",
    "else: print(\"file already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a5d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_fite_path, sep = \"\\t\", header = None, names = [\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34061f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab8610a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(df[\"Label\"].value_counts().spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af0a3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     747\n",
       "spam    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_subset = df[df[\"Label\"] == \"ham\"].sample(int(df[\"Label\"].value_counts().spam))\n",
    "balanced_df = pd.concat((ham_subset, df[df[\"Label\"] == \"spam\"])).reset_index(drop = True)\n",
    "balanced_df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ac55bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Are you not around or just still asleep? :V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>THANX 4 PUTTIN DA FONE DOWN ON ME!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi dear we saw dear. We both are happy. Where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>R u in this continent?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm very happy for you babe ! Woo hoo party on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham        Are you not around or just still asleep? :V\n",
       "1      ham                THANX 4 PUTTIN DA FONE DOWN ON ME!!\n",
       "2      ham  Hi dear we saw dear. We both are happy. Where ...\n",
       "3      ham                             R u in this continent?\n",
       "4      ham  I'm very happy for you babe ! Woo hoo party on...\n",
       "...    ...                                                ...\n",
       "1489  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "1490  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "1491  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "1492  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "1493  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdae78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ham = 0\n",
    "# spam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21d36d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you not around or just still asleep? :V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>THANX 4 PUTTIN DA FONE DOWN ON ME!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi dear we saw dear. We both are happy. Where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>R u in this continent?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm very happy for you babe ! Woo hoo party on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "0         0        Are you not around or just still asleep? :V\n",
       "1         0                THANX 4 PUTTIN DA FONE DOWN ON ME!!\n",
       "2         0  Hi dear we saw dear. We both are happy. Where ...\n",
       "3         0                             R u in this continent?\n",
       "4         0  I'm very happy for you babe ! Woo hoo party on...\n",
       "...     ...                                                ...\n",
       "1489      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "1490      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "1491      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "1492      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "1493      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1640ab59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 149, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_split(df :pd.DataFrame, train_split, val_split):\n",
    "    assert (train_split > 0 )and (train_split < 1)\n",
    "    assert (val_split > 0) and (val_split < 1)\n",
    "\n",
    "    shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    n = len(df)\n",
    "    train_end = int(train_split * n)\n",
    "    val_end = train_end + int(val_split * n)\n",
    "\n",
    "    train_df = shuffled_df.iloc[:train_end]\n",
    "    val_df   = shuffled_df.iloc[train_end:val_end]\n",
    "    test_df  = shuffled_df.iloc[val_end:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3124bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index = None)\n",
    "val_df.to_csv(\"val.csv\", index = None)\n",
    "test_df.to_csv(\"test.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed00314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer.decode([50256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5a4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length = None, pad_token = 50256):\n",
    "        \n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.encoded_text = [tokenizer.encode(text) for text in self.df[\"Text\"]]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_text = [encoded_text[:self.max_length] for encoded_text in self.encoded_text]\n",
    "\n",
    "        # padding\n",
    "        self.encoded_text = [\n",
    "            encoded_text + [pad_token] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_text\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_text[index]\n",
    "        label = self.df.iloc[index][\"Label\"]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "            )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        return max(len(encoded_text) for encoded_text in self.encoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "141ca2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "                    csv_file=\"train.csv\",\n",
    "                    tokenizer=tokenizer,\n",
    "                )\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "                    csv_file=\"val.csv\",\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_length=train_dataset.max_length\n",
    "                )\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "                    csv_file=\"test.csv\",\n",
    "                    tokenizer=tokenizer,\n",
    "                    max_length=train_dataset.max_length\n",
    "                )\n",
    "\n",
    "train_dataset.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95322a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01946e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef147e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 120])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f23b3862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c86f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62a25e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
    "\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\"     : tokenizer.n_vocab, # 50257\n",
    "    \"context_length\" : 1024,                  # The maximum number of tokens the model can process at once\n",
    "    \"embedding_dim\"  : 768,                   # The number of features used to represent each token \n",
    "    \"n_heads\"        : 12,\n",
    "    \"n_layers\"       : 12,                    # How many transformer blocks\n",
    "    \"drop_rate\"      : 0.1,\n",
    "    \"qkv_bias\"       : False\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "device = \"cpu\"\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e6f165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " your hair is winter fire.\n",
      "Cancer, when left-hooked on the back of their penis\n",
      "fans it and their hair, and then like all hair-on-your-head it'll explode in the fire from a\n",
      "mesh. Not to be confused by the two, as I'm told they've really only given them the \"two of y-too high. a fussy.\"\n",
      "\n",
      "\n",
      "If it was you\n",
      "\n",
      "There's too many things out there and I won't get it.\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    tokens=text_to_token_ids(\"your hair is winter fire\", tokenizer).to(device),\n",
    "    max_new_tokens=100,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5,\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac3cf9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for params in gpt.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "for params in gpt.transformer_blocks[-1].parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "for params in gpt.final_norm.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "gpt.out_head = torch.nn.Linear(in_features = 768, out_features = num_classes)\n",
    "gpt.out_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7fa0d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.3902, -1.0732]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"do you have time\")\n",
    "logits = gpt(torch.tensor(input_ids).unsqueeze(0))[:, -1, :]\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e5f192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.argmax(logits, dim = -1).item()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9337a9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_accuracy(data_loader, model, device, num_batches = None):\n",
    "    model.eval()\n",
    "    correct_preds, viewed_classes = 0, 0\n",
    "    if num_batches:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    else:\n",
    "        num_batches = len(data_loader)\n",
    "    \n",
    "    for idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if idx < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "                pred_labels = torch.argmax(logits, dim = -1)\n",
    "\n",
    "            correct_preds += (pred_labels == target_batch).sum().item()\n",
    "            viewed_classes += input_batch.shape[0]\n",
    "        else: break\n",
    "        \n",
    "    model.train()\n",
    "    return correct_preds / viewed_classes\n",
    "\n",
    "calc_accuracy(train_loader, gpt, \"cpu\", num_batches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9148d8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897229689359665"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    return torch.nn.functional.cross_entropy(logits, target_batch) # loss\n",
    "\n",
    "def calc_loss_loader(dataloader, model, device, num_batches = None):\n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len (dataloader))\n",
    "\n",
    "    total_loss = 0\n",
    "    for idx, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        if idx < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else: break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "calc_loss_loader(train_loader, gpt, \"cpu\", num_batches = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82b10f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(model      : torch.nn.Module,\n",
    "                train_loader: DataLoader,\n",
    "                val_loader  : DataLoader,\n",
    "                optimizer   : torch.optim.Optimizer,\n",
    "                num_epochs  : int,\n",
    "                eval_freq   : int,\n",
    "                eval_iter   : int,\n",
    "                device      : str):\n",
    "    \n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in tqdm(train_loader, total=len(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    train_loss = calc_loss_loader(train_loader, model, device, num_batches = eval_iter)\n",
    "                    val_loss = calc_loss_loader(val_loader, model, device, num_batches = eval_iter)\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                model.train()\n",
    "\n",
    "                print(f\"Epoch: {epoch} | train loss: {train_loss:.3f} | val loss: {val_loss:.3f}\")\n",
    "\n",
    "\n",
    "        # after every batch calculate accuracy\n",
    "        train_acc = calc_accuracy(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_acc   = calc_accuracy(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        print(f\"Training accuracy: {train_acc*100:.2f}% | \", end=\"\") \n",
    "        print(f\"Validation accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b0a44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embedding): Embedding(50257, 768)\n",
       "  (position_embedding): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MutliHeadAttention(\n",
       "        (W_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Feedforward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\"     : tokenizer.n_vocab, # 50257\n",
    "    \"context_length\" : 1024,                  # The maximum number of tokens the model can process at once\n",
    "    \"embedding_dim\"  : 768,                   # The number of features used to represent each token \n",
    "    \"n_heads\"        : 12,\n",
    "    \"n_layers\"       : 12,                    # How many transformer blocks\n",
    "    \"drop_rate\"      : 0.1,\n",
    "    \"qkv_bias\"       : False\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "model = GPTModel(NEW_CONFIG)\n",
    "device = \"cpu\"\n",
    "load_weights_into_gpt(model, params)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c00a4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "for params in model.transformer_blocks[-1].parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "for params in model.final_norm.parameters():\n",
    "    params.requires_grad = True\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model.out_head = torch.nn.Linear(in_features = 768, out_features = num_classes)\n",
    "\n",
    "for p in model.out_head.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "model.out_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aff5cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/130 [00:05<10:49,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 5.909 | val loss: 5.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 51/130 [00:39<02:23,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 1.260 | val loss: 1.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 101/130 [01:12<00:52,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 0.831 | val loss: 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:29<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 55.00% | Validation accuracy: 60.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 21/130 [00:16<03:17,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train loss: 0.568 | val loss: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 71/130 [00:49<01:47,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train loss: 0.960 | val loss: 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 121/130 [01:22<00:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train loss: 0.548 | val loss: 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [01:28<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 70.00% | Validation accuracy: 77.50%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_simple(model       = model,\n",
    "                                                                            train_loader = train_loader,\n",
    "                                                                            val_loader   = val_loader,\n",
    "                                                                            optimizer    = optimizer,\n",
    "                                                                            num_epochs   = num_epochs,\n",
    "                                                                            eval_freq    = 50,\n",
    "                                                                            eval_iter    = 5,\n",
    "                                                                            device       = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3757146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ac9fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_or_not(model, text, pad_token, max_len):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    input_ids = tokens + [pad_token] * abs(len(tokens) - max_len)\n",
    "    input_tensor = torch.tensor(input_ids).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a69de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not spam'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = \"hello, how are you\"\n",
    "pad_token = 50256\n",
    "max_len = train_dataset.max_length\n",
    "\n",
    "spam_or_not(model, t1, pad_token = 50256, max_len = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8963ce9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not spam'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "spam_or_not(model, t2, pad_token = 50256, max_len = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a5406df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "spam_or_not(model, t3, pad_token = 50256, max_len = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fca20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f9c7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57072717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
