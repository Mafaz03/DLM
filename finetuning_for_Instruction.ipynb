{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6960bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from helper import *\n",
    "from knowledge_transfer import load_weights_into_gpt\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from model import GPTModel\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7ab69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
       "  'input': 'freind --> friend',\n",
       "  'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'},\n",
       " {'instruction': 'Edit the following sentence for grammar.',\n",
       "  'input': 'He go to the park every day.',\n",
       "  'output': 'He goes to the park every day.'},\n",
       " {'instruction': 'Convert 45 kilometers to meters.',\n",
       "  'input': '',\n",
       "  'output': '45 kilometers is 45000 meters.'},\n",
       " {'instruction': \"Rewrite this sentence to start with 'Although': Despite the rain, they went for a walk.\",\n",
       "  'input': '',\n",
       "  'output': 'Although it was raining, they went for a walk.'},\n",
       " {'instruction': 'What are the first 10 square numbers?',\n",
       "  'input': '',\n",
       "  'output': '1, 4, 9, 16, 25, 36, 49, 64, 81, 100.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "file_name = \"instruction-data.json\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    response = requests.get(link)\n",
    "    text_data = response.text\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(text_data)\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d07649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd45f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n"
     ]
    }
   ],
   "source": [
    "def prompt_style(dictonary: dict):\n",
    "\n",
    "\n",
    "    header = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "    if \"instruction\" in dictonary and len(dictonary[\"instruction\"]) != 0:\n",
    "        header += \"\\n\\n### Instruction:\"\n",
    "        header += f\"\\n{dictonary['instruction']}\"\n",
    "\n",
    "    if \"input\" in dictonary and len(dictonary[\"input\"]) != 0:\n",
    "        header += \"\\n\\n### Input:\"\n",
    "        header += f\"\\n{dictonary['input']}\"\n",
    "    # else:\n",
    "    #     if header == None: header = \"\"\n",
    "    #     if \"output\" in dictonary and len(dictonary[\"output\"]) != 0:\n",
    "    #         header += \"### Output:\"\n",
    "    #         header += f\"\\n{dictonary['output']}\"\n",
    "\n",
    "    return header\n",
    "\n",
    "print(prompt_style(data[999]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e3cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response: \n",
      " An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = prompt_style(data[0])\n",
    "desired_output = f\"\\n\\n### Response: \\n {data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc0c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.85\n",
    "test_frac = 0.1\n",
    "val_frac = abs(train_frac - test_frac)\n",
    "\n",
    "train_portion = int(len(data) * train_frac)\n",
    "test_portion  = int(len(data) * test_frac)\n",
    "val_portion   = int(len(data) * val_frac)\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data  = data[train_portion: train_portion + test_portion]\n",
    "val_data   = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788593d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935, 110, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "298722fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer.encode(model_input)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f7ad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Instruction_dataset(Dataset):\n",
    "    def __init__(self, data: list[dict], tokenizer):\n",
    "        \n",
    "        self.encoded_data: list[str] = []\n",
    "        for d in data:\n",
    "            model_input = prompt_style(d)\n",
    "            desired_output = f\"\\n\\n### Response: \\n {d['output']}\"\n",
    "            full_text = model_input + desired_output\n",
    "        \n",
    "            self.encoded_data.append(tokenizer.encode(full_text))\n",
    "    def __getitem__(self, index) -> list[str]:\n",
    "        return self.encoded_data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_data)\n",
    "    \n",
    "ins_dataset = Instruction_dataset(data, tokenizer)\n",
    "sample_data = next(iter(ins_dataset))\n",
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461fedf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     2,     3,     4, 50256, 50256, 50256],\n",
       "        [    6,     7,    10,     3,     4,     6,     6],\n",
       "        [    3, 50256, 50256, 50256, 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_function(batch, padding_token_id: int = 50256, ignore_index = -100, allowed_max_length = None, device: str = \"cpu\"):\n",
    "    max_length_of_batch = max(len(item)+1 for item in batch)\n",
    "\n",
    "    inputs_list = []\n",
    "    target_list = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [padding_token_id]\n",
    "\n",
    "        padded = new_item + [padding_token_id] * (max_length_of_batch - len(new_item))\n",
    "        \n",
    "        # remove the extra +1 we did in line 2, line 2 differs if not in noteboook\n",
    "        inputs_padded = torch.tensor(padded[:-1])\n",
    "        targets_padded = torch.tensor(padded[1:])\n",
    "\n",
    "    \n",
    "        mask = targets_padded == padding_token_id\n",
    "        indices = torch.nonzero(mask).squeeze() # returns indexes\n",
    "        if indices.numel() > 1: # more than one padding token id\n",
    "            targets_padded[indices[1: ]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs_padded  = inputs_padded[:allowed_max_length]\n",
    "            targets_padded = targets_padded[:allowed_max_length]\n",
    "\n",
    "        inputs_list.append(inputs_padded)\n",
    "        target_list.append(targets_padded)\n",
    "    \n",
    "    \n",
    "    return torch.stack(inputs_list, dim = 0).to(device), torch.stack(target_list, dim = 0).to(device)\n",
    "\n",
    "\n",
    "batch_ex = (\n",
    "    [1, 2, 3, 4],\n",
    "    [6, 7, 10, 3, 4, 6, 6],\n",
    "    [3,]\n",
    ")\n",
    "\n",
    "input_tensor, target_tensor = collate_function(batch_ex, padding_token_id=50256, allowed_max_length=None)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747f3041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     3,     4, 50256,  -100,  -100,  -100],\n",
       "        [    7,    10,     3,     4,     6,     6, 50256],\n",
       "        [50256,  -100,  -100,  -100,  -100,  -100,  -100]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c50abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2,3,4] == [3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7cc03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_deivce():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\" \n",
    "    elif torch.mps.is_available():\n",
    "        return \"mps\" \n",
    "    return \"cpa\"\n",
    "\n",
    "get_deivce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341b64ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function collate_function at 0x114096840>, device='mps', allowed_max_length=1024)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customized_collate_function = partial(collate_function, device = get_deivce(), allowed_max_length = 1024)\n",
    "customized_collate_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c4b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 0\n",
    "\n",
    "train_dataset = Instruction_dataset(train_data, tokenizer)\n",
    "val_dataset   = Instruction_dataset(val_data, tokenizer)\n",
    "test_dataset  = Instruction_dataset(test_data, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(dataset     = train_dataset, \n",
    "                              batch_size  = batch_size, \n",
    "                              collate_fn  = customized_collate_function, \n",
    "                              shuffle     = True, \n",
    "                              drop_last   = True, \n",
    "                              num_workers = num_workers)\n",
    "\n",
    "val_dataloader = DataLoader(dataset       = val_dataset, \n",
    "                              batch_size  = batch_size, \n",
    "                              collate_fn  = customized_collate_function, \n",
    "                              shuffle     = False, \n",
    "                              drop_last   = False, \n",
    "                              num_workers = num_workers)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(dataset      = test_dataset, \n",
    "                              batch_size  = batch_size, \n",
    "                              collate_fn  = customized_collate_function, \n",
    "                              shuffle     = False, \n",
    "                              drop_last   = False, \n",
    "                              num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1a13f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 83]), torch.Size([8, 83]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, targets = next(iter(train_dataloader))\n",
    "inputs.shape, targets.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4007b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide a synonym for 'fast'.\n",
      "\n",
      "### Response: \n",
      " A synonym for 'fast' is 'quick'.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438eb56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide a synonym for 'fast'.\n",
      "\n",
      "### Response: \n",
      " A synonym for 'fast' is 'quick'.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "mask = targets[0] == -100\n",
    "masked_target = torch.nonzero(mask)\n",
    "print(\n",
    "    tokenizer.decode(targets[0][:-len(masked_target)].tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61068019",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"355M\", models_dir=\"gpt2\")\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\"     : tokenizer.n_vocab, # 50257\n",
    "    \"context_length\" : 1024,                  # The maximum number of tokens the model can process at once\n",
    "    \"embedding_dim\"  : 768,                   # The number of features used to represent each token \n",
    "    \"n_heads\"        : 12,\n",
    "    \"n_layers\"       : 12,                    # How many transformer blocks\n",
    "    \"drop_rate\"      : 0.1,\n",
    "    \"qkv_bias\"       : False\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"embedding_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"embedding_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"embedding_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"embedding_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-medium (355M)\"\n",
    "\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "model = GPTModel(NEW_CONFIG)\n",
    "device = get_deivce()\n",
    "load_weights_into_gpt(model, params)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b6277ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 1024])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.token_embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b166ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c66fa55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "input_text = prompt_style(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c80aa4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_to_token_ids(text, tokenizer):\n",
    "#     # return torch.tensor(tokenizer.encode(text, allowed_special=\"<|endoftext|>\")).unsqueeze(0)\n",
    "\n",
    "#     return torch.tensor(\n",
    "#                 tokenizer.encode(\n",
    "#                         text,\n",
    "#                         allowed_special={\"<|endoftext|>\"}\n",
    "#                     ), device=get_deivce()\n",
    "#             ).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37df3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62cf2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "            model = model,\n",
    "            tokens = text_to_token_ids(input_text, tokenizer, \"cpu\"),\n",
    "            max_new_tokens = 35,\n",
    "            context_size = NEW_CONFIG[\"context_length\"],\n",
    "            eos_id = 50256,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b0db43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef is a chef. The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Write the response that is appropriate for the task.\n"
     ]
    }
   ],
   "source": [
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(generated_text[len(input_text):].replace(\"### Response:\", \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bed86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024cd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75757c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
